{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# https://penseeartificielle.fr/methode-google-comprendre-sens-mots-word-embedding-python-gensim/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Corpus 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "documents = [\n",
    "\"le chat mange ses croquettes\",\n",
    "\"le chien aime ses croquettes\",\n",
    "\"le chat ronronne et mange\"\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Vecteurs TF-IDF de tous les mots dans chaque document"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "import pandas as pd\n",
    "\n",
    "tfidf_vectorizer = TfidfVectorizer()\n",
    "tfidf_vector = tfidf_vectorizer.fit_transform(documents)\n",
    " \n",
    "pd.DataFrame(\n",
    "    tfidf_vector.toarray(),\n",
    "    columns=tfidf_vectorizer.get_feature_names(),\n",
    "    index=[f\"doc_{i+1}\" for i in range(len(documents))]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Distance (cosinus) vectorielle entre 2 documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.spatial.distance import cosine\n",
    "def print_cosine(i_doc1,i_doc2):\n",
    "    print('doc1:',documents[i_doc1])\n",
    "    print('doc2:',documents[i_doc2])\n",
    "    print(cosine(\n",
    "        tfidf_vector.toarray()[i_doc1],\n",
    "        tfidf_vector.toarray()[i_doc2]\n",
    "    ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# docs proches\n",
    "print_cosine(0,2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# docs éloignés\n",
    "print_cosine(1,2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Corpus 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "documents = [\n",
    "\"le chat mange ses croquettes\",\n",
    "\"le chien dévore ses croquettes\",\n",
    "\"le chat dévore son paté\",\n",
    "\"jean va travailler\",\n",
    "\"le chat mange son repas\",\n",
    "\"jacque aime quand son chien mange\"\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Calcul du contexte (bag of words) global d'un mot à partir de chaque document"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "contexts = defaultdict(list)\n",
    "bag_size = 1\n",
    "for phrase in documents:\n",
    "    words = phrase.split()\n",
    "    print()\n",
    "    print('phrase:',words)\n",
    "    # foreach word of a phrase by index, adjust context of the word \n",
    "    for i, word in enumerate(words):\n",
    "        # index candidates for context\n",
    "        candidate = [i+j for j in range (0-bag_size,1+bag_size) if j != 0]\n",
    "        # local words context \n",
    "        bag_of_words = [words[c] for c in candidate if 0 <= c < len(words)]\n",
    "        print('  + ',i,word,' | local bow:',bag_of_words)\n",
    "        # add local context to global context\n",
    "        contexts[word] = contexts[word] + bag_of_words\n",
    "    print()\n",
    "    display('New global context:',contexts)\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prepare TF-IDF of documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer = TfidfVectorizer()\n",
    "vectorizer.fit(documents)\n",
    "print(vectorizer.get_feature_names())\n",
    "print(documents[0])\n",
    "print(vectorizer.transform([documents[0]],len(vectorizer.get_feature_names())))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Calcul pour chaque mot, cacul du vecteur TF-IDF du contexte (vu comme un document)\n",
    "\n",
    "Si l’hypothèse distributionnelle est exacte, ces vecteurs de contexte peuvent être considérés comme des vecteurs de sens.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectors = {}\n",
    "n_features = 2\n",
    "for k, v in contexts.items():\n",
    "    str_ = ' '.join(v)\n",
    "    print(k,' - context: ',v,' -sentence: ', str_)\n",
    "    vectors[k] = vectorizer.transform([str_], n_features)[0]\n",
    "    print(vectors[k])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Calcul de la similarité entre un mot un un autre en calculant la distance entre leur vecteur respectif de contexte"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def most_similar(word):\n",
    "    scores = []\n",
    "    keys_ = [k for k in vectors.keys() if k != word]\n",
    "    for k in keys_:\n",
    "        # to avoid \"ValueError: dimension mismatch\" -> .toarray() create a dense array (not optimal!) \n",
    "        scores.append(\n",
    "          1-cosine(\n",
    "              vectors[word].toarray(),\n",
    "              vectors[k].toarray()\n",
    "          )\n",
    "        )\n",
    "    return pd.Series(\n",
    "        scores,\n",
    "        index=keys_\n",
    "      ).sort_values(ascending=False)#.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(documents)\n",
    "most_similar('chat')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
